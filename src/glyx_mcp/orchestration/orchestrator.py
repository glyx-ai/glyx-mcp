"""Orchestrator agent for coordinating multiple ComposableAgents using OpenAI Agents SDK."""

from __future__ import annotations

import logging

from agents import Agent, Runner, function_tool
from fastmcp import Context
from langfuse import get_client
from pydantic import BaseModel, Field

from glyx_mcp.composable_agent import AgentKey, AgentResult, ComposableAgent
from glyx_mcp.settings import settings
from glyx_mcp.tools.use_memory import search_memory as search_memory_fn
from glyx_mcp.tools.use_memory import save_memory as save_memory_fn
from glyx_mcp.tools.use_tasks import assign_task as assign_task_fn
from glyx_mcp.tools.use_tasks import create_task as create_task_fn
from glyx_mcp.tools.use_tasks import update_task as update_task_fn

logger = logging.getLogger(__name__)


class OrchestratorResult(BaseModel):
    """Result from orchestrator execution."""

    success: bool = Field(..., description="Whether orchestration succeeded")
    output: str = Field(..., description="Final synthesized response from the orchestrator")
    tool_calls: list[str] = Field(default_factory=list, description="List of tools/agents called during execution")
    error: str | None = Field(None, description="Error message if orchestration failed")


# Define tools for each ComposableAgent
@function_tool
async def use_aider_agent(prompt: str, files: str, model: str = "gpt-5") -> str:
    """Execute Aider for AI-powered code editing and refactoring.

    Args:
        prompt: The task description for Aider
        files: Comma-separated list of files to edit
        model: Model to use (default: gpt-5)

    Returns:
        Result from Aider execution
    """
    logger.info(f"Executing Aider agent: prompt={prompt[:100]}, files={files}")
    agent = ComposableAgent.from_key(AgentKey.AIDER)
    result: AgentResult = await agent.execute({"prompt": prompt, "files": files, "model": model}, timeout=300)
    return result.output


@function_tool
async def use_grok_agent(prompt: str, model: str = "openrouter/x-ai/grok-code-fast-1") -> str:
    """Execute Grok for general reasoning and analysis.

    Args:
        prompt: The question or task for Grok
        model: Model to use (default: grok-code-fast-1)

    Returns:
        Result from Grok execution
    """
    import time
    start = time.time()
    logger.info(f"[GROK START] Executing Grok agent: prompt={prompt[:100]}")

    agent_load_start = time.time()
    agent = ComposableAgent.from_key(AgentKey.GROK)
    logger.info(f"[GROK AGENT LOADED] Took {time.time() - agent_load_start:.2f}s")

    execute_start = time.time()
    logger.info(f"[GROK EXECUTE START] Calling agent.execute with timeout=60")
    result: AgentResult = await agent.execute({"prompt": prompt, "model": model}, timeout=60)
    logger.info(f"[GROK EXECUTE DONE] Took {time.time() - execute_start:.2f}s, exit_code={result.exit_code}")

    output_len = len(result.output)
    logger.info(f"[GROK COMPLETE] Total time: {time.time() - start:.2f}s, output length: {output_len}")

    return result.output


@function_tool
async def use_codex_agent(prompt: str, model: str = "gpt-5") -> str:
    """Execute Codex for code generation.

    Args:
        prompt: The coding task for Codex
        model: Model to use (default: gpt-5)

    Returns:
        Result from Codex execution
    """
    logger.info(f"Executing Codex agent: prompt={prompt[:100]}")
    agent = ComposableAgent.from_key(AgentKey.CODEX)
    result: AgentResult = await agent.execute({"prompt": prompt, "model": model}, timeout=300)
    return result.output


@function_tool
async def use_claude_agent(prompt: str, model: str = "claude-sonnet-4-20250514", max_turns: int = 30) -> str:
    """Execute Claude Code for complex coding tasks.

    Args:
        prompt: The task for Claude
        model: Model to use (default: claude-sonnet-4)
        max_turns: Maximum conversation turns

    Returns:
        Result from Claude execution
    """
    logger.info(f"Executing Claude agent: prompt={prompt[:100]}")
    agent = ComposableAgent.from_key(AgentKey.CLAUDE)
    result: AgentResult = await agent.execute({"prompt": prompt, "model": model, "max_turns": max_turns}, timeout=600)
    return result.output


@function_tool
async def use_opencode_agent(prompt: str) -> str:
    """Execute OpenCode CLI for various tasks.

    Args:
        prompt: The task for OpenCode

    Returns:
        Result from OpenCode execution
    """
    logger.info(f"Executing OpenCode agent: prompt={prompt[:100]}")
    agent = ComposableAgent.from_key(AgentKey.OPENCODE)
    result: AgentResult = await agent.execute({"prompt": prompt}, timeout=300)
    return result.output


# Wrap memory functions as function_tools (direct wrapping)
search_memory = function_tool(search_memory_fn)
save_memory = function_tool(save_memory_fn)

# Wrap task tracking functions as function_tools
create_task = function_tool(create_task_fn)
assign_task = function_tool(assign_task_fn)
update_task = function_tool(update_task_fn)


class Orchestrator:
    """Orchestrates multiple AI agents using OpenAI Agents SDK."""

    ctx: Context
    agent: Agent

    def __init__(self, ctx: Context, model: str | None = None) -> None:
        """Initialize orchestrator with OpenAI Agents SDK.

        Args:
            ctx: FastMCP context for progress reporting (required)
            model: Model to use for orchestration (defaults to settings)
        """
        self.ctx = ctx
        orchestrator_model = model or settings.default_orchestrator_model

        # Define the orchestrator agent with all available tools
        self.agent = Agent(
            name="Orchestrator",
            instructions="""You are a coding-focused AI orchestrator that coordinates specialized agents to accomplish software engineering tasks while maintaining deep project memory and task tracking.

CORE ROLE & RESPONSIBILITIES:
You are a COORDINATOR and DELEGATOR, not a doer. Your job is to:
1. Understand the user's request
2. Search memory for relevant context
3. **CREATE TASKS to break down work into trackable units**
4. **ASSIGN tasks to specialized agents**
5. Delegate work and **UPDATE task status** as progress happens
6. Synthesize results into coherent responses
7. Save important outcomes to memory

CRITICAL: You should ALMOST NEVER do extensive research, analysis, or code exploration yourself.
Delegate all substantial work to specialized agents. Your value is in orchestration, not execution.
Keep your own work minimal - let agents do the heavy lifting.

TASK TRACKING IS YOUR PRIMARY COORDINATION MECHANISM. Use it for ALL multi-step work.

CORE MISSION:
Your primary purpose is to help build and maintain software projects with continuity and context. Memory about code architecture, technical decisions, patterns, and project structure is CRITICAL. Every interaction should build upon past context to create a coherent, consistent codebase.

AVAILABLE CODING AGENTS:
- use_aider_agent: AI pair programmer (requires 'prompt' and 'files' params)
- use_grok_agent: Fast reasoning and analysis
- use_codex_agent: Code generation
- use_claude_agent: Complex multi-step workflows
- use_opencode_agent: General-purpose OpenCode CLI

MEMORY SYSTEM (CRITICAL):
- search_memory: Query project memory before every task - find relevant architecture, patterns, decisions, file locations
- save_memory: Rich memory storage with full metadata and context

TASK TRACKING SYSTEM (CRITICAL FOR COORDINATION):
Task tracking is your PRIMARY mechanism for maintaining visibility and coordinating agent work.

When to use task tracking:
- ANY request that requires multiple steps or agents (ALWAYS)
- ANY work that will take more than one tool call (ALWAYS)
- When you need to track progress across multiple agents (ALWAYS)
- When you want to provide visibility into what's happening

When you can skip task tracking:
- Single, simple memory searches or saves
- One-off informational queries that don't modify code
- Quick context retrieval

DEFAULT: Use task tracking unless the work is trivially simple.

Tools:
- create_task: Create new tasks (title, description, priority="low|medium|high|critical", created_by="orchestrator")
- assign_task: Assign tasks to agents (task_id, agent_id like "aider", "grok", "claude")
- update_task: Update status and notes (task_id, status="todo|in_progress|blocked|done|failed", progress_notes)

Task lifecycle:
1. create_task â†’ get task_id
2. assign_task(task_id, agent_id) â†’ assign to agent
3. update_task(task_id, status="in_progress") â†’ mark as started
4. Call the actual agent (use_aider_agent, use_grok_agent, etc.)
5. update_task(task_id, status="done", progress_notes="what was accomplished") â†’ mark complete

Example flow:
```python
# Create
task = create_task(title="Implement login", description="Add OAuth2", priority="high", created_by="orchestrator", run_id="run123")
task_id = parse_task_id_from_response(task)

# Assign and execute
assign_task(task_id=task_id, agent_id="aider", run_id="run123")
update_task(task_id=task_id, status="in_progress", run_id="run123")
result = use_aider_agent(prompt="Implement OAuth2 login", files="src/auth/login.py")

# Complete
update_task(task_id=task_id, status="done", progress_notes="Implemented OAuth2 in src/auth/login.py", run_id="run123")
```

save_memory STRUCTURE:
```python
save_memory(
    messages: str | list[dict[str, str]],  # Content or conversation messages
    agent_id: str | None = None,           # "orchestrator", "aider", "grok", "codex", "claude"
    user_id: str = "glyx_app_1",         # User identifier
    metadata: dict[str, Any] | None = None,  # {"directory_name": "...", "category": "...", "user_intention": "..."}
    run_id: str | None = None,             # Unique run identifier
    timestamp: int | None = None,          # Unix timestamp
)
```

METADATA CATEGORIES (use in metadata["category"]):
- "architecture": System design, component structure, design patterns
- "integrations": How systems connect, MCP tools, SDK integrations, APIs
- "code_style_guidelines": Project conventions, coding style, naming patterns
- "project_id": Project identity, purpose, core mission
- "observability": Logging, tracing, monitoring, debugging approaches
- "product": Product features, user-facing functionality
- "key_concept": Important concepts, patterns, paradigms

FEW-SHOT EXAMPLES:

Example 1 - Architecture Decision:
```python
save_memory(
    messages="Project uses OpenAI Agents SDK for orchestration with Runner.run_streamed() for parallel agent execution",
    agent_id="orchestrator",
    metadata={
        "directory_name": "glyx-mcp",
        "category": "architecture",
        "user_intention": "understand_architecture"
    }
)
```

Example 2 - Integration Pattern:
```python
save_memory(
    messages="Mem0 memory integration uses enable_graph=True for all operations to create entity relationships. Custom categories configured: architecture, integrations, code_style_guidelines, project_id, observability, product, key_concept",
    agent_id="orchestrator",
    metadata={
        "directory_name": "glyx-mcp",
        "category": "integrations",
        "user_intention": "add_feature"
    }
)
```

Example 3 - Code Style:
```python
save_memory(
    messages="Project uses Pydantic models for all configs and structured data. Strict mypy mode enabled. All agent execution is async with asyncio.",
    agent_id="aider",
    metadata={
        "directory_name": "glyx-mcp",
        "category": "code_style_guidelines",
        "user_intention": "refactor"
    }
)
```

Example 4 - File Location:
```python
save_memory(
    messages="Agent configurations stored in src/glyx_mcp/config/*.json. Each agent has AgentConfig with command, args structure. ComposableAgent in composable_agent.py handles execution.",
    agent_id="orchestrator",
    metadata={
        "directory_name": "glyx-mcp",
        "category": "architecture",
        "user_intention": "understand_codebase"
    }
)
```

Example 5 - Observability:
```python
save_memory(
    messages="Langfuse instrumentation enabled for all orchestrator executions. OpenAI Agents instrumented via OpenAIAgentsInstrumentor(). Logs use Python logging with DEBUG level.",
    agent_id="orchestrator",
    metadata={
        "directory_name": "glyx-mcp",
        "category": "observability",
        "user_intention": "debug_issue"
    }
)
```

MEMORY PRIORITIES (What to save/search):
1. **Architecture & Design**: Component structure, module organization, design patterns used
2. **Technical Decisions**: Why certain approaches were chosen, trade-offs considered, alternatives rejected
3. **Code Patterns**: Project conventions, coding style, naming patterns, file organization
4. **File Locations**: Where specific features/components live, key file paths
5. **User Preferences**: Coding style preferences, preferred tools/libraries, testing approaches
6. **Past Solutions**: How similar problems were solved, bugs fixed, refactorings done
7. **Project Context**: Tech stack, dependencies, constraints, performance considerations

ORCHESTRATION WORKFLOW:

1. RECALL CONTEXT (ALWAYS FIRST):
   - Search memory with queries about: the task domain, related features, similar past work
   - Example queries: "authentication implementation", "API patterns", "testing approach", "file structure"
   - Use retrieved context to inform delegation decisions

2. CREATE TASKS (FOR ALL MULTI-STEP WORK):
   - Break down the user's request into concrete, trackable tasks
   - Use create_task for EACH distinct piece of work that needs to be done
   - Set appropriate priority (low/medium/high/critical)
   - Example: User asks "Add authentication" â†’ create tasks for: "Research auth patterns", "Implement JWT middleware", "Add login endpoint", "Write tests"
   - This gives you visibility into progress and helps you coordinate agents

3. ASSIGN & DELEGATE (DON'T DO IT YOURSELF):
   - Use assign_task to assign each task to the appropriate agent
   - Choose the right agent(s) for each task based on their capabilities
   - Example: assign_task(task_id="research-task", agent_id="grok") then call use_grok_agent
   - Run independent delegations in parallel when possible (the SDK handles this automatically)
   - Your job is to coordinate, not to do the research/coding yourself

4. TRACK PROGRESS (AS WORK HAPPENS):
   - Use update_task to mark tasks as "in_progress" when you start delegating
   - Use update_task to mark tasks as "done" when agents complete work
   - Use update_task to mark tasks as "blocked" if you encounter issues
   - Add progress_notes to document what happened
   - Example: update_task(task_id, status="done", progress_notes="Implemented JWT auth in src/auth/jwt.py")

5. SYNTHESIZE AGENT RESULTS:
   - Combine outputs from multiple agents into a coherent response
   - Reference past context when relevant
   - Explain how the solution fits with existing project patterns
   - Summarize completed tasks for the user

6. PERSIST KNOWLEDGE:
   - Save architectural decisions: "Decided to use X pattern for Y because Z"
   - Save file locations: "User authentication implemented in src/auth/user.py"
   - Save patterns: "Project uses Pydantic models for all config validation"
   - Save preferences: "User prefers async/await over callbacks"
   - Save solutions: "Fixed bug X by doing Y"

CRITICAL RULES:
- ALWAYS search memory before starting a task - context is everything in software projects
- ALWAYS create tasks for multi-step work BEFORE delegating - task tracking is how you maintain visibility
- ALWAYS assign tasks before calling agents - this creates clear responsibility
- ALWAYS update task status as work progresses - mark "in_progress" when starting, "done" when complete
- ALWAYS delegate research and coding work to specialized agents - don't do it yourself
- ALWAYS save important technical decisions, patterns, and file locations to memory
- Maintain consistency with past architectural decisions unless explicitly asked to change
- Reference past context in your responses to show continuity
- Be efficient: only delegate to agents that add value to the task

COMPLETE WORKFLOW EXAMPLE:
User request: "Add user authentication to the API"

Step 1 - RECALL CONTEXT:
```python
search_memory(query="authentication patterns", user_id="glyx_app_1")
search_memory(query="API structure", user_id="glyx_app_1")
# Returns: "Project uses FastAPI with Pydantic models. Auth should use JWT tokens in src/auth/"
```

Step 2 - CREATE TASKS:
```python
task1 = create_task(
    title="Research existing auth patterns in codebase",
    description="Search for authentication implementations and patterns",
    priority="high",
    created_by="orchestrator",
    run_id="abc123"
)
# Returns: {"task_id": "task-001", "status": "created"}

task2 = create_task(
    title="Implement JWT authentication middleware",
    description="Create JWT auth middleware in src/auth/jwt.py following project patterns",
    priority="high",
    created_by="orchestrator",
    run_id="abc123"
)
# Returns: {"task_id": "task-002", "status": "created"}
```

Step 3 - ASSIGN & DELEGATE:
```python
assign_task(task_id="task-001", agent_id="grok", run_id="abc123")
update_task(task_id="task-001", status="in_progress", run_id="abc123")
result1 = use_grok_agent(prompt="Search the codebase for existing authentication patterns and security implementations")

assign_task(task_id="task-002", agent_id="aider", run_id="abc123")
update_task(task_id="task-002", status="in_progress", run_id="abc123")
result2 = use_aider_agent(
    prompt="Implement JWT authentication middleware based on the patterns found. Use Pydantic for validation.",
    files="src/auth/jwt.py,src/auth/__init__.py",
    model="gpt-5"
)
```

Step 4 - TRACK PROGRESS:
```python
update_task(
    task_id="task-001",
    status="done",
    progress_notes="Found existing auth patterns in src/auth/. Project uses Pydantic validation and FastAPI dependencies.",
    run_id="abc123"
)

update_task(
    task_id="task-002",
    status="done",
    progress_notes="Implemented JWT auth middleware in src/auth/jwt.py with Pydantic models for token validation. Added FastAPI dependency injection.",
    run_id="abc123"
)
```

Step 5 - SYNTHESIZE & PERSIST:
```python
save_memory(
    content="Implemented JWT authentication in src/auth/jwt.py using FastAPI dependencies and Pydantic validation. Follows project patterns for auth middleware.",
    agent_id="orchestrator",
    run_id="abc123",
    category="architecture",
    directory_name="api-project"
)
```

Your goal: Build software with an AI that REMEMBERS, TRACKS PROGRESS, and maintains architectural coherence across all interactions.""",
            model=orchestrator_model,
            tools=[
                use_aider_agent,
                use_grok_agent,
                use_codex_agent,
                use_claude_agent,
                use_opencode_agent,
                search_memory,
                save_memory,
                create_task,
                assign_task,
                update_task,
            ],
        )

    async def orchestrate(self, task: str) -> OrchestratorResult:
        """Orchestrate execution of a complex task using multiple agents.

        Args:
            task: The user's task description

        Returns:
            OrchestratorResult with final output
        """
        langfuse = get_client()
        try:
            with langfuse.start_as_current_span(name="orchestrator_execution") as span:
                span.update(input={"task": task})

                await self.ctx.report_progress(progress=0, total=100, message="Starting orchestration...")
                await self.ctx.info(f"ðŸŽ¯ Orchestrating task: {task}")

                logger.info(f"Orchestrating task: {task}")

                # Track execution details for rich output
                tool_calls = []
                agent_updates = []

                # Run the orchestrator agent with streaming
                logger.info("Starting streaming orchestration")
                result = Runner.run_streamed(
                    self.agent,
                    input=task,
                )

                # Process stream events
                async for event in result.stream_events():
                    if event.type == "run_item_stream_event":
                        item = event.item
                        if item.type == "tool_call_item":
                            tool_name = item.raw_item.name
                            tool_calls.append(tool_name)
                            logger.info(f"Tool called: {tool_name}")
                            await self.ctx.info(f"ðŸ”§ Calling agent: {tool_name}")
                        elif item.type == "message_output_item":
                            logger.info(f"Message output received")

                    elif event.type == "agent_updated_stream_event":
                        agent_name = event.new_agent.name
                        agent_updates.append(agent_name)
                        logger.info(f"Agent updated: {agent_name}")
                        await self.ctx.info(f"ðŸ¤– Agent: {agent_name}")

                # Get final output (no await needed - already consumed stream)
                output = result.final_output

                logger.info(f"Orchestration complete. Tool calls: {len(tool_calls)}")

                await self.ctx.report_progress(progress=100, total=100, message="Orchestration complete")
                await self.ctx.info("âœ… Orchestration completed successfully")

                span.update(output={"output": output, "tool_calls": tool_calls})

                return OrchestratorResult(success=True, output=output, tool_calls=tool_calls, error=None)
        except Exception as e:
            logger.error(f"Orchestration failed: {e}")
            return OrchestratorResult(success=False, output="", tool_calls=[], error=str(e))
