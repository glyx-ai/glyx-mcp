"""FastMCP server for coding agents with Aider integration."""

from __future__ import annotations

import logging
import sys

from fastmcp import FastMCP, Context
from fastmcp.utilities.logging import get_logger
from langfuse import get_client, observe

from glyx_mcp.orchestration.orchestrator import Orchestrator
from glyx_mcp.settings import settings
from glyx_mcp.tools.use_aider import use_aider
from glyx_mcp.tools.use_grok import use_grok
from glyx_mcp.tools.use_opencode import use_opencode

# Configure logging to output to both file and stderr with DEBUG level

langfuse = get_client()
langfuse.auth_check()

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stderr),
    ],
    force=True,
)

logger = logging.getLogger(__name__)

# Configure FastMCP client logging (messages sent to MCP clients)
to_client_logger = get_logger(name="fastmcp.server.context.to_client")
to_client_logger.setLevel(level=logging.DEBUG)


mcp = FastMCP("glyx-mcp")

# Register tools with MCP server
mcp.tool(use_aider)
mcp.tool(use_grok)
mcp.tool(use_opencode)

# Register prompts - hardcoded for simplicity
@mcp.prompt
async def orchestrate_prompt(
    task: str,
    ctx: Context,
) -> str:
    """
    Orchestrate complex tasks by coordinating multiple AI agents with deep reasoning and stuff.
    """
    orchestrator = Orchestrator(ctx=ctx, model="gpt-5")
    result = await orchestrator.orchestrate(task)

    # Build rich text output with detailed orchestration info
    output_parts = [
        "# ðŸŽ¯ Orchestration Report",
        "",
        "## ðŸ“‹ Task",
        f"> {task}",
        "",
        "## âš™ï¸ Configuration",
        f"- **Model**: gpt-5",
        f"- **Available Agents**: aider, grok, codex, claude, opencode",
        f"- **Status**: {'âœ… Success' if result.success else 'âŒ Failed'}",
        "",
        "## ðŸ¤– Agent Coordination",
        "",
        "The orchestrator analyzed the task and determined the optimal execution strategy.",
        "Agents were called as needed through the OpenAI Agents SDK.",
        "",
        "## ðŸ’¡ Result",
        "",
        result.output,
        "",
        "---",
        "*Generated by glyx-mcp orchestrator*"
    ]

    return "\n".join(output_parts)

@observe
def main() -> None:
    """Run the FastMCP server."""
    mcp.run()


if __name__ == "__main__":
    main()
