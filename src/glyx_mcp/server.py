"""FastMCP server for coding agents with Aider integration."""

from __future__ import annotations

import logging
import sys

from fastmcp import FastMCP, Context
from fastmcp.utilities.logging import get_logger
from langfuse import Langfuse, observe

from glyx_mcp.orchestration.orchestrator import Orchestrator
from glyx_mcp.settings import settings
from glyx_mcp.tools.use_aider import use_aider
from glyx_mcp.tools.use_grok import use_grok
from glyx_mcp.tools.use_opencode import use_opencode
from openinference.instrumentation.openai_agents import OpenAIAgentsInstrumentor

LOG_FILE = "/app/logs/glyx-mcp.log"

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stderr),
        logging.FileHandler(LOG_FILE, mode='a'),
    ],
    force=True,
)

logger = logging.getLogger(__name__)


langfuse = Langfuse(
    public_key=settings.langfuse_public_key,
    secret_key=settings.langfuse_secret_key,
    host=settings.langfuse_host,
)
if not langfuse.auth_check():
    raise RuntimeError(
        "Langfuse authentication failed. Please check LANGFUSE_PUBLIC_KEY, "
        "LANGFUSE_SECRET_KEY, and LANGFUSE_HOST in your .env file."
    )
logger.info("Langfuse instrumented. Preparing OpenAI agent instrumentation...")
OpenAIAgentsInstrumentor().instrument()



# Configure FastMCP client logging (messages sent to MCP clients)
to_client_logger = get_logger(name="fastmcp.server.context.to_client")
to_client_logger.setLevel(level=logging.DEBUG)


mcp = FastMCP("glyx-mcp")

# Register tools with MCP server
logger.info("Initializing MCP tools...")
mcp.tool(use_aider)
mcp.tool(use_grok)
mcp.tool(use_opencode)

# Register resources
@mcp.resource("logs://glyx-mcp")
async def get_logs() -> str:
    """View the glyx-mcp server logs."""
    try:
        with open(LOG_FILE, 'r') as f:
            lines = f.readlines()
            # Return last 500 lines
            return ''.join(lines[-500:])
    except FileNotFoundError:
        return "No logs available yet."
    except Exception as e:
        return f"Error reading logs: {e}"

# Register prompts - hardcoded for simplicity
@mcp.prompt
async def orchestrate_prompt(
    task: str,
    ctx: Context,
) -> str:
    """
    Orchestrate complex tasks by coordinating multiple AI agents with deep reasoning and stuff.
    """
    orchestrator = Orchestrator(ctx=ctx, model="gpt-5")
    result = await orchestrator.orchestrate(task)

    # Build rich text output with detailed orchestration info
    output_parts = [
        "# ðŸŽ¯ Orchestration Report",
        "",
        "## ðŸ“‹ Task",
        f"> {task}",
        "",
        "## âš™ï¸ Configuration",
        f"- **Model**: gpt-5",
        f"- **Available Agents**: aider, grok, codex, claude, opencode",
        f"- **Status**: {'âœ… Success' if result.success else 'âŒ Failed'}",
        "",
        "## ðŸ¤– Agent Execution",
        "",
    ]

    if result.tool_calls:
        output_parts.append(f"**Agents Called**: {len(result.tool_calls)}")
        output_parts.append("")
        for i, tool in enumerate(result.tool_calls, 1):
            output_parts.append(f"{i}. `{tool}`")
        output_parts.append("")
    else:
        output_parts.append("The orchestrator handled the task directly without delegating to specialized agents.")
        output_parts.append("")

    output_parts.extend([
        "## ðŸ’¡ Result",
        "",
        result.output,
        "",
        "---",
        "*Generated by glyx-mcp orchestrator with streaming*"
    ])

    return "\n".join(output_parts)

@observe
def main() -> None:
    """Run the FastMCP server."""
    mcp.run()


if __name__ == "__main__":
    main()
